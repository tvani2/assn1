{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5407,"databundleVersionId":868283,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)  \npd.set_option('display.width', None)        \npd.set_option('display.expand_frame_repr', False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cleaning","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop(columns=['SalePrice'])\ny = df['SalePrice']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cols_to_drop = ['PoolQC', 'MiscFeature', 'Alley', 'Fence'] # too many missing values\nX_train.drop(cols_to_drop, axis=1, inplace=True)\nX_test.drop(cols_to_drop, axis=1, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ids = X_train.pop('Id')\ntest_ids = X_test.pop('Id')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(X_train.isna().mean().sort_values(ascending=False).head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.drop('GarageYrBlt', axis=1, inplace=True)\nX_test.drop('GarageYrBlt', axis=1, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Engineering\n","metadata":{}},{"cell_type":"code","source":"cat_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\nnum_cols = [col for col in X_train.columns if X_train[col].dtype != 'object']\n\nprint(f\"Categorical columns ({len(cat_cols)}): {cat_cols}\")\nprint(f\"Numerical columns ({len(num_cols)}): {num_cols}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in cat_cols:\n    print(X_train[col].value_counts()) # სვეტში რა ობიექტი რამდენჯერ გვხვდება","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"s = X_train[cat_cols].nunique()\ns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n = X_train[num_cols].nunique()\nn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def analyze_numericals(df, num_cols):\n    analysis = []\n    for col in num_cols:\n        # Basic stats\n        value_counts = df[col].value_counts(dropna=False)\n        n_unique = len(value_counts)\n        na_count = df[col].isna().sum()\n        \n        # Dominant category percentage\n        dominant_pct = (value_counts.iloc[0] / len(df)) * 100\n        \n        analysis.append({\n            'Column': col,\n            'Unique Values': n_unique,\n            'NA Values': na_count,\n            'Dominant Value': value_counts.index[0],\n            'Dominant %': round(dominant_pct, 1),\n            'Value Counts': value_counts.to_dict()\n        })\n    \n    return pd.DataFrame(analysis)\n\ncat_analysis = analyze_numericals(X_train, num_cols)\npd.set_option('display.max_rows', None)\nprint(cat_analysis[['Column', 'Unique Values', 'NA Values', 'Dominant Value', 'Dominant %']])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ncols_to_check = [\n    'LowQualFinSF',       # 95% 'Gtl' (almost no variance)\n    'PoolArea',      # 92% 'Y' (nearly all paved)\n    'MiscVal',      # 92% 'SBrkr' (dominant category)\n    '3SsnPorch',\n    'LotFrontage',\n    'FireplaceQu',\n    'MasVnrArea'\n]\n\nfor col in cols_to_check:\n    if col in X_train.columns:\n        plt.figure(figsize=(8, 4))\n        sns.boxplot(x=X_train[col], y=y_train)\n        plt.title(f\"SalePrice by {col}\")\n        plt.xticks(rotation=45)\n        plt.tight_layout()\n        plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\n# Separate data into complete and incomplete records\ntrain = X_train[X_train['LotFrontage'].notna()]\npredict = X_train[X_train['LotFrontage'].isna()]\n\n# Simple model using just LotArea (could add more features)\nmodel = LinearRegression()\nmodel.fit(np.log1p(train['LotArea'].values.reshape(-1, 1)), train['LotFrontage'])\n\n# Predict missing values\npredicted_frontage = model.predict(np.log1p(predict['LotArea'].values.reshape(-1, 1)))\n\n# Update X_train with the predicted values\nX_train.loc[X_train['LotFrontage'].isna(), 'LotFrontage'] = predicted_frontage","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.drop(columns=['PoolArea'], inplace=True)\nX_test.drop(columns=['PoolArea'], inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train['MasVnrArea'] = X_train['MasVnrArea'].fillna(0)\nX_test['MasVnrArea'] = X_test['MasVnrArea'].fillna(0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\n\ncols_to_drop = ['Street', 'Utilities', 'Condition2', 'RoofMatl']\n\n# Create a figure with subplots\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\naxes = axes.ravel()\n\nfor i, col in enumerate(cols_to_drop):\n    if col in X_train.columns:\n        # Calculate value counts and percentages\n        value_counts = X_train[col].value_counts()\n        percentages = X_train[col].value_counts(normalize=True) * 100\n        \n        # Create a DataFrame for display\n        df_display = pd.DataFrame({\n            'Count': value_counts,\n            'Percentage (%)': percentages.round(1)\n        })\n        \n        print(f\"\\nValue distribution for {col}:\")\n        print(df_display)\n        \n        # Plot the distribution\n        value_counts.plot(kind='bar', ax=axes[i], color='skyblue')\n        axes[i].set_title(f'Distribution of {col}')\n        axes[i].set_xlabel('')\n        axes[i].set_ylabel('Count')\n        \n        # Add percentage labels\n        for p in axes[i].patches:\n            axes[i].annotate(f'{p.get_height()}\\n({p.get_height()/len(X_train)*100:.1f}%)', \n                           (p.get_x() + p.get_width() / 2., p.get_height()), \n                           ha='center', va='center', xytext=(0, 10), \n                           textcoords='offset points')\n    else:\n        print(f\"\\nColumn {col} not found in training data\")\n\nplt.tight_layout()\nplt.show()\n\n# Now actually drop the columns\nX_train.drop(columns=cols_to_drop, inplace=True, errors='ignore')\nX_test.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n\nprint(\"\\nColumns dropped successfully.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols = [col for col in cat_cols if col not in cols_to_drop]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def analyze_categoricals(df, cat_cols):\n    analysis = []\n    for col in cat_cols:\n        # Basic stats\n        value_counts = df[col].value_counts(dropna=False)\n        n_unique = len(value_counts)\n        na_count = df[col].isna().sum()\n        \n        # Dominant category percentage\n        dominant_pct = (value_counts.iloc[0] / len(df)) * 100\n        \n        analysis.append({\n            'Column': col,\n            'Unique Values': n_unique,\n            'NA Values': na_count,\n            'Dominant Value': value_counts.index[0],\n            'Dominant %': round(dominant_pct, 1),\n            'Value Counts': value_counts.to_dict()\n        })\n    \n    return pd.DataFrame(analysis)\n\ncat_analysis = analyze_categoricals(X_train, cat_cols)\npd.set_option('display.max_rows', None)\nprint(cat_analysis[['Column', 'Unique Values', 'NA Values', 'Dominant Value', 'Dominant %']])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train['GarageCond_Problem'] = (X_train['GarageCond'] != 'TA').astype(int)\nX_test['GarageCond_Problem'] = (X_test['GarageCond'] != 'TA').astype(int)\n\nX_train.drop(columns=['GarageCond'], inplace=True)\nX_test.drop(columns=['GarageCond'], inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"threshold = 3\n\nwoe_columns = list(s[s > 3].index)\none_hot_columns = list(s[s <= 3].index)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_woe_columns = [col for col in woe_columns if col in X_train.columns]\nX_train[valid_woe_columns].mode().T[0].to_dict()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nimport pandas as pd\nimport numpy as np\n\nclass CustomPreprocessor(BaseEstimator, TransformerMixin):\n    def __init__(self, woe_columns, one_hot_columns):\n        self.woe_columns = woe_columns\n        self.one_hot_columns = one_hot_columns\n\n    def fit(self, X, y):\n        # Store mode values for WOE columns\n        self.woe_columns_fill_na = X[self.woe_columns].mode().T[0].to_dict()\n        \n        # Calculate WOE and IV\n        df_woe = X[self.woe_columns].copy()\n        df_woe['SalePrice'] = y\n        \n        self.woe_mappings = {}\n        self.iv_values = {}\n        \n        for col in self.woe_columns:\n            # Group by category and calculate metrics\n            groups = df_woe.groupby(col)['SalePrice'].agg(['count', 'mean'])\n            groups['n_pos'] = groups['mean'] * groups['count']\n            groups['n_neg'] = groups['count'] - groups['n_pos']\n            \n            # Calculate proportions\n            total_pos = groups['n_pos'].sum()\n            total_neg = groups['n_neg'].sum()\n            groups['prop_pos'] = groups['n_pos'] / total_pos\n            groups['prop_neg'] = groups['n_neg'] / total_neg\n            \n            # Calculate WOE and IV\n            groups['woe'] = np.log(groups['prop_pos'] / groups['prop_neg'])\n            groups['iv'] = (groups['prop_pos'] - groups['prop_neg']) * groups['woe']\n            \n            # Clean infinite/NA values\n            groups.replace([np.inf, -np.inf, np.nan], 0, inplace=True)\n            \n            # Store mappings\n            self.woe_mappings[col] = groups['woe'].to_dict()\n            self.iv_values[col] = groups['iv'].sum()\n\n        return self\n\n    def transform(self, X):\n        X_transformed = X.copy()\n        \n        # Apply WOE encoding\n        for col in self.woe_columns:\n            new_col = f'{col}_woe'\n            # Map values and handle NAs in one step\n            X_transformed[new_col] = (\n                X_transformed[col]\n                .map(self.woe_mappings[col])\n                .fillna(self.woe_mappings[col].get(self.woe_columns_fill_na[col], 0))\n            )\n        \n        # One-hot encode remaining categoricals\n        X_transformed = pd.get_dummies(\n            X_transformed,\n            columns=self.one_hot_columns,\n            drop_first=True,\n            dummy_na=True\n        )\n        \n        # Drop original columns safely\n        cols_to_drop = [c for c in (self.woe_columns + self.one_hot_columns) \n                       if c in X_transformed.columns]\n        X_transformed = X_transformed.drop(columns=cols_to_drop)\n        \n        # Final NA clean-up (shouldn't be needed if dummy_na=True)\n        return X_transformed.fillna(0)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_one_hot_columns = [col for col in one_hot_columns if col in X_train.columns]\npreprocessor = CustomPreprocessor(\n    woe_columns=valid_woe_columns,\n    one_hot_columns=valid_one_hot_columns\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_t = preprocessor.fit_transform(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_t = preprocessor.transform(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_test_t.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_t.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature selection","metadata":{}},{"cell_type":"code","source":"X_corr = X_train_t.copy()\nX_corr['SalePrice'] = y_train","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"available_cols = [col for col in X_corr.columns if col != 'SalePrice']\ncorr_matrix = X_corr[available_cols + ['SalePrice']].corr().abs()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"corr_matrix","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_and_drop_high_correlations(df, target_col='SalePrice', threshold=0.8):\n    \"\"\"\n    1. Finds only feature pairs with correlation > threshold\n    2. Clearly shows which feature to drop from each pair\n    3. Returns filtered pairs and drop list\n    \"\"\"\n    # Calculate correlations\n    corr_matrix = df.corr().abs()\n    \n    # Get upper triangle without diagonal\n    mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)\n    high_corr = corr_matrix.where(mask > threshold).stack().reset_index()\n    high_corr.columns = ['Feature1', 'Feature2', 'Correlation']\n    \n    # Filter strictly above threshold\n    high_corr = high_corr[high_corr['Correlation'] > threshold]\n    \n    if not high_corr.empty:\n        # Calculate target correlations\n        target_corrs = df.corr()[target_col].abs()\n        \n        # Add target correlation info\n        high_corr['Feature1_TargetCorr'] = high_corr['Feature1'].map(target_corrs)\n        high_corr['Feature2_TargetCorr'] = high_corr['Feature2'].map(target_corrs)\n        \n        # Determine which to drop\n        high_corr['Drop'] = high_corr.apply(\n            lambda x: x['Feature1'] if x['Feature1_TargetCorr'] < x['Feature2_TargetCorr'] else x['Feature2'],\n            axis=1\n        )\n        \n        # Sort and display\n        high_corr = high_corr.sort_values('Correlation', ascending=False)\n        print(f\"Features with correlation > {threshold}:\")\n        display(high_corr[['Feature1', 'Feature2', 'Correlation', \n                          'Feature1_TargetCorr', 'Feature2_TargetCorr', 'Drop']])\n        \n        # Get unique features to drop\n        features_to_drop = list(high_corr['Drop'].unique())\n        print(f\"\\nRecommended features to drop: {features_to_drop}\")\n        \n        return df.drop(columns=features_to_drop), features_to_drop\n    else:\n        print(f\"No feature pairs with correlation > {threshold}\")\n        return df, []\n# Usage\nX_train_reduced, dropped_features = find_and_drop_high_correlations(\n    X_corr, \n    target_col='SalePrice'\n)","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features_to_drop =  ['GarageArea', 'Exterior1st_woe', '1stFlrSF', 'TotRmsAbvGrd', \n                     'SaleCondition_woe', 'MasVnrType_BrkFace']\nX_filtered = X_train_t.drop(columns=features_to_drop)\nX_test_new = X_test_t.drop(columns=features_to_drop)\nprint(f\"Original shape: {X_train_t.shape}, New shape: {X_filtered.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_filtered.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer, mean_squared_error\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n# Standardize the data\nscaler = StandardScaler()\nX_train_scaled = pd.DataFrame(\n    scaler.fit_transform(X_filtered),\n    columns=X_filtered.columns\n)\n\n# Prepare the model\nmodel = LinearRegression()\n\n# Store results\nresults = []\n\n# Define scoring metrics\nscoring = {\n    'r2': 'r2',\n    'rmse': make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)))\n}\n\n# Test different feature counts\nfeature_counts = [10, 15, 20, 25, 30, 35, 40]\n\nfor n_features in feature_counts:\n    rfe = RFE(estimator=model, n_features_to_select=n_features, step=1)\n    rfe.fit(X_train_scaled, y_train)\n    \n    # Get selected features\n    selected_features = X_filtered.columns[rfe.support_].tolist()\n    X_selected = X_train_scaled[selected_features]\n    \n    # Cross-validation with multiple metrics\n    cv_r2 = cross_val_score(model, X_selected, y_train, cv=5, scoring='r2').mean()\n    cv_rmse = -cross_val_score(model, X_selected, y_train, cv=5, \n                              scoring='neg_root_mean_squared_error').mean()\n    \n    # Store all results\n    results.append({\n        'n_features': n_features,\n        'features': selected_features,\n        'r2': cv_r2,\n        'rmse': cv_rmse\n    })\n    \n    print(f\"RFE with {n_features} features selected:\")\n    print(f\"R²: {cv_r2:.4f}, RMSE: {cv_rmse:.4f}\")\n    print(f\"Features: {selected_features}\\n\")\n\n# Convert results to DataFrame for easier analysis\nresults_df = pd.DataFrame(results)\n\n# Find best features by R²\nbest_r2_idx = results_df['r2'].idxmax()\nbest_features_r2 = results_df.loc[best_r2_idx, 'features']\nbest_n_r2 = results_df.loc[best_r2_idx, 'n_features']\n\n# Find best features by RMSE\nbest_rmse_idx = results_df['rmse'].idxmin()\nbest_features_rmse = results_df.loc[best_rmse_idx, 'features']\nbest_n_rmse = results_df.loc[best_rmse_idx, 'n_features']\n\nprint(f\"\\nBest by R² ({results_df.loc[best_r2_idx, 'r2']:.4f}):\")\nprint(f\"{best_n_r2} features: {best_features_r2}\")\n\nprint(f\"\\nBest by RMSE ({results_df.loc[best_rmse_idx, 'rmse']:.4f}):\")\nprint(f\"{best_n_rmse} features: {best_features_rmse}\")\n\n# Plot the results\nplt.figure(figsize=(12, 5))\n\n# R² plot\nplt.subplot(1, 2, 1)\nplt.plot(results_df['n_features'], results_df['r2'], marker='o', linestyle='-', color='b')\nplt.title('Cross-validated R² Score')\nplt.xlabel('Number of Features Selected')\nplt.ylabel('R² Score')\nplt.axvline(x=best_n_r2, color='r', linestyle='--', alpha=0.3)\nplt.grid(True)\n\n# RMSE plot\nplt.subplot(1, 2, 2)\nplt.plot(results_df['n_features'], results_df['rmse'], marker='o', linestyle='-', color='g')\nplt.title('Cross-validated RMSE')\nplt.xlabel('Number of Features Selected')\nplt.ylabel('RMSE')\nplt.axvline(x=best_n_rmse, color='r', linestyle='--', alpha=0.3)\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()\n\n# Store the best feature sets (you can access these later)\nBest_features_r2 = best_features_r2\nBest_features_rmse = best_features_rmse\nBest_n_r2 = best_n_r2\nBest_n_rmse = best_n_rmse","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Best_features_r2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"!pip install dagshub mlflow","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import dagshub\ndagshub.init(repo_owner='tvani2', repo_name='assn1', mlflow=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# L1","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\n\n# Start MLflow experiment and run\nmlflow.set_experiment(\"House Price Regression\")\n\nwith mlflow.start_run(run_name=\"L1\") as run:\n    # Log basic parameters\n    mlflow.log_params({\n        \"model\": \"Lasso\",\n        \"cv_folds\": 5,\n        \"scoring\": \"neg_root_mean_squared_error\",\n        \"search_type\": \"GridSearchCV\"\n    })\n\n    # Fit the model\n    grid_search.fit(X_filtered, y_train)\n\n    # Log best parameters\n    mlflow.log_params(grid_search.best_params_)\n\n    # Log best cross-validation RMSE\n    best_rmse_cv = -grid_search.best_score_\n    mlflow.log_metric(\"cv_rmse\", best_rmse_cv)\n\n    # Test set evaluation (if available)\n    if 'X_test_new' in locals():\n        y_pred = grid_search.predict(X_test_new)\n        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n        r2_test = r2_score(y_test, y_pred)\n        mlflow.log_metric(\"test_rmse\", rmse_test)\n        mlflow.log_metric(\"test_r2\", r2_test)\n\n    # Feature importance logging\n    best_lasso = grid_search.best_estimator_.named_steps['regressor']\n    feature_importance = pd.DataFrame({\n        'Feature': X_filtered.columns,\n        'Coefficient': best_lasso.coef_,\n        'Absolute_Coeff': np.abs(best_lasso.coef_)\n    }).sort_values('Absolute_Coeff', ascending=False)\n    \n    # Save top 10 features to CSV and log as artifact\n    top_features_path = \"top_features.csv\"\n    feature_importance.head(10).to_csv(top_features_path, index=False)\n    mlflow.log_artifact(top_features_path)\n\n    # Log the full model\n    mlflow.sklearn.log_model(grid_search.best_estimator_, \"model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Set MLflow experiment\nmlflow.set_experiment(\"House Price Regression\")\n\nwith mlflow.start_run(run_name=\"L1 new alphas\"):\n    # Define pipeline\n    pipeline = Pipeline([\n        ('scaler', MinMaxScaler()),\n        ('regressor', Lasso(random_state=42))\n    ])\n\n    # Hyperparameter grid\n    alphas = np.logspace(0, 3, 20)\n    param_grid = {\n        'scaler': [MinMaxScaler()],\n        'regressor__alpha': alphas,\n        'regressor__selection': ['random']\n    }\n\n    # K-Fold cross-validation\n    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\n    # Grid search\n    grid_search = GridSearchCV(\n        pipeline,\n        param_grid=param_grid,\n        cv=kfold,\n        scoring='neg_root_mean_squared_error',\n        verbose=2,\n        n_jobs=-1,\n        return_train_score=True\n    )\n\n    # Fit the model\n    grid_search.fit(X_filtered, y_train)\n\n    # Log parameters (convert non-serializables to strings!)\n    mlflow.log_param(\"scaler\", \"MinMaxScaler\")\n    mlflow.log_param(\"selection\", \"random\")\n    mlflow.log_param(\"alpha_range\", \"logspace(0, 3, 20)\")\n    mlflow.log_param(\"best_alpha\", grid_search.best_params_['regressor__alpha'])\n\n    # Log best CV RMSE\n    best_rmse_cv = -grid_search.best_score_\n    mlflow.log_metric(\"cv_rmse\", best_rmse_cv)\n\n    # Evaluate on test set\n    if 'X_test_new' in locals():\n        y_pred = grid_search.predict(X_test_new)\n        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n        r2_test = r2_score(y_test, y_pred)\n        mlflow.log_metric(\"test_rmse\", rmse_test)\n        mlflow.log_metric(\"test_r2\", r2_test)\n\n    # Log feature importance\n    best_lasso = grid_search.best_estimator_.named_steps['regressor']\n    feature_importance = pd.DataFrame({\n        'Feature': X_filtered.columns,\n        'Coefficient': best_lasso.coef_,\n        'Absolute_Coeff': np.abs(best_lasso.coef_)\n    }).sort_values('Absolute_Coeff', ascending=False)\n\n    # Save and log top features\n    top_features_path = \"top_features_L1_new_alphas.csv\"\n    feature_importance.head(10).to_csv(top_features_path, index=False)\n    mlflow.log_artifact(top_features_path)\n\n    # Log model\n    mlflow.sklearn.log_model(grid_search.best_estimator_, \"model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nresults = pd.DataFrame(grid_search.cv_results_)\nalphas = results['param_regressor__alpha'].astype(float)\nrmse = -results['mean_test_score']\n\nplt.figure(figsize=(8,5))\nplt.plot(alphas, rmse, marker='o')\nplt.xscale('log')\nplt.xlabel('Alpha')\nplt.ylabel('CV RMSE')\nplt.title('Validation Curve')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# L2","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Set experiment\nmlflow.set_experiment(\"House Price Regression\")\n\nwith mlflow.start_run(run_name=\"L2\"):\n    # Define pipeline\n    pipeline = Pipeline([\n        ('scaler', StandardScaler()),\n        ('regressor', Ridge(random_state=42))\n    ])\n\n    # Hyperparameter grid\n    alphas = np.logspace(-3, 3, 50)\n    param_grid = {\n        'scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n        'regressor__alpha': alphas\n    }\n\n    # K-Fold CV\n    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\n    # Scoring\n    scoring = {\n        'rmse': 'neg_root_mean_squared_error',\n        'r2': 'r2'\n    }\n\n    # Grid search\n    grid_search = GridSearchCV(\n        pipeline,\n        param_grid=param_grid,\n        cv=kfold,\n        scoring=scoring,\n        refit='rmse',\n        verbose=2,\n        n_jobs=-1,\n        return_train_score=True\n    )\n\n    # Fit model\n    grid_search.fit(X_filtered, y_train)\n\n    # Log best params (with scaler name converted to string)\n    best_params = grid_search.best_params_\n    mlflow.log_param(\"scaler\", type(best_params['scaler']).__name__)\n    mlflow.log_param(\"best_alpha\", best_params['regressor__alpha'])\n\n    # Log CV metrics\n    best_rmse_cv = -grid_search.best_score_\n    results_df = pd.DataFrame(grid_search.cv_results_)\n    best_r2_cv = results_df.loc[grid_search.best_index_, 'mean_test_r2']\n    mlflow.log_metric(\"cv_rmse\", best_rmse_cv)\n    mlflow.log_metric(\"cv_r2\", best_r2_cv)\n\n    # Evaluate on test set\n    if 'X_test_new' in locals():\n        y_pred = grid_search.predict(X_test_new)\n        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n        r2_test = r2_score(y_test, y_pred)\n        mlflow.log_metric(\"test_rmse\", rmse_test)\n        mlflow.log_metric(\"test_r2\", r2_test)\n\n    # Feature importance\n    best_ridge = grid_search.best_estimator_.named_steps['regressor']\n    feature_importance = pd.DataFrame({\n        'Feature': X_filtered.columns,\n        'Coefficient': best_ridge.coef_,\n        'Absolute_Coeff': np.abs(best_ridge.coef_)\n    }).sort_values('Absolute_Coeff', ascending=False)\n\n    # Save & log top 10 features\n    top_features_path = \"top_features_L2.csv\"\n    feature_importance.head(10).to_csv(top_features_path, index=False)\n    mlflow.log_artifact(top_features_path)\n\n    # Log model\n    mlflow.sklearn.log_model(grid_search.best_estimator_, \"model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ElasticNet","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Set experiment\nmlflow.set_experiment(\"House Price Regression\")\n\nwith mlflow.start_run(run_name=\"ElasticNet\"):\n    # Define pipeline\n    pipeline = Pipeline([\n        ('scaler', StandardScaler()),  # Placeholder\n        ('regressor', ElasticNet(random_state=42, max_iter=10000))\n    ])\n\n    # Parameter grid\n    param_grid = {\n        'scaler': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n        'regressor__alpha': np.logspace(-3, 3, 10),\n        'regressor__l1_ratio': np.linspace(0.1, 0.9, 5),\n        'regressor__selection': ['cyclic', 'random']\n    }\n\n    # Cross-validation\n    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n\n    # Scoring\n    scoring = {\n        'rmse': 'neg_root_mean_squared_error',\n        'r2': 'r2'\n    }\n\n    # Grid Search\n    grid_search = GridSearchCV(\n        pipeline,\n        param_grid=param_grid,\n        cv=kfold,\n        scoring=scoring,\n        refit='rmse',\n        verbose=2,\n        n_jobs=-1,\n        return_train_score=True\n    )\n\n    # Fit model\n    grid_search.fit(X_filtered, y_train)\n\n    # Extract best params\n    best_params = grid_search.best_params_\n    mlflow.log_param(\"scaler\", type(best_params['scaler']).__name__)\n    mlflow.log_param(\"alpha\", best_params['regressor__alpha'])\n    mlflow.log_param(\"l1_ratio\", best_params['regressor__l1_ratio'])\n    mlflow.log_param(\"selection\", best_params['regressor__selection'])\n\n    # Cross-validation results\n    best_rmse_cv = -grid_search.best_score_\n    results_df = pd.DataFrame(grid_search.cv_results_)\n    best_r2_cv = results_df.loc[grid_search.best_index_, 'mean_test_r2']\n\n    mlflow.log_metric(\"cv_rmse\", best_rmse_cv)\n    mlflow.log_metric(\"cv_r2\", best_r2_cv)\n\n    print(\"\\nBest parameters:\", best_params)\n    print(\"Best CV RMSE:\", best_rmse_cv)\n    print(\"Best CV R²:\", best_r2_cv)\n\n    # Evaluate on test set if available\n    if 'X_test_new' in locals():\n        y_pred = grid_search.predict(X_test_new)\n        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred))\n        r2_test = r2_score(y_test, y_pred)\n\n        mlflow.log_metric(\"test_rmse\", rmse_test)\n        mlflow.log_metric(\"test_r2\", r2_test)\n\n        print(\"\\nTest set performance:\")\n        print(f\"RMSE: {rmse_test:.4f}\")\n        print(f\"R²: {r2_test:.4f}\")\n\n    # Feature importance\n    best_model = grid_search.best_estimator_.named_steps['regressor']\n    feature_importance = pd.DataFrame({\n        'Feature': X_filtered.columns,\n        'Coefficient': best_model.coef_,\n        'Absolute_Coeff': np.abs(best_model.coef_)\n    }).sort_values('Absolute_Coeff', ascending=False)\n\n    print(\"\\nTop 10 most important features:\")\n    print(feature_importance.head(10))\n\n    # Save top 10 features\n    top_features_path = \"top_features_elasticnet.csv\"\n    feature_importance.head(10).to_csv(top_features_path, index=False)\n    mlflow.log_artifact(top_features_path)\n\n    # Log the model\n    mlflow.sklearn.log_model(grid_search.best_estimator_, \"model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Original shape: {X_train.shape}\")  # Likely (n_samples, 72)\nprint(f\"Effective features used: {(best_model.coef_ != 0).sum()}\")  # 55","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# L2 on limited data","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score\n\n# Set MLflow experiment\nmlflow.set_experiment(\"House Price Regression\")\n\n# Select the best features\nX_train_best = X_filtered[Best_features_r2]\n\n# Define alpha values to test\nalphas = np.logspace(-3, 3, 50)\n\n# Store results\nridge_results = []\n\nwith mlflow.start_run(run_name=\"L2 with limited features\"):\n    # Loop through alpha values\n    for alpha in alphas:\n        ridge = Ridge(alpha=alpha)\n\n        # Cross-validation\n        cv_r2 = cross_val_score(ridge, X_train_best, y_train, cv=5, scoring='r2').mean()\n        cv_rmse = -cross_val_score(ridge, X_train_best, y_train, cv=5, \n                                  scoring='neg_root_mean_squared_error').mean()\n\n        ridge_results.append({\n            'alpha': alpha,\n            'r2': cv_r2,\n            'rmse': cv_rmse\n        })\n\n    # Convert results to DataFrame\n    ridge_results_df = pd.DataFrame(ridge_results)\n\n    # Find best alpha values\n    best_alpha_r2 = ridge_results_df.loc[ridge_results_df['r2'].idxmax(), 'alpha']\n    best_r2 = ridge_results_df['r2'].max()\n    best_alpha_rmse = ridge_results_df.loc[ridge_results_df['rmse'].idxmin(), 'alpha']\n    best_rmse = ridge_results_df['rmse'].min()\n\n    # Log best parameters and metrics\n    mlflow.log_param(\"best_alpha_r2\", best_alpha_r2)\n    mlflow.log_param(\"best_alpha_rmse\", best_alpha_rmse)\n    mlflow.log_metric(\"best_r2\", best_r2)\n    mlflow.log_metric(\"best_rmse\", best_rmse)\n\n    # Fit final model using best R² alpha\n    final_ridge = Ridge(alpha=best_alpha_r2)\n    final_ridge.fit(X_train_best, y_train)\n\n    # Log model\n    mlflow.sklearn.log_model(final_ridge, \"ridge_model_limited_features\")\n\n    # Feature importances\n    ridge_coefs = pd.DataFrame({\n        'feature': Best_features_r2,\n        'coefficient': final_ridge.coef_\n    }).sort_values('coefficient', key=abs, ascending=False)\n\n    # Log top 10 features\n    top_features_str = ridge_coefs.head(10).to_string(index=False)\n    mlflow.log_text(top_features_str, \"top_10_features.txt\")\n\n    # Optional: Save and log the plots\n    plt.figure(figsize=(12, 5))\n\n    plt.subplot(1, 2, 1)\n    plt.semilogx(ridge_results_df['alpha'], ridge_results_df['r2'])\n    plt.title('Ridge Regression R² vs Alpha')\n    plt.xlabel('Alpha (log scale)')\n    plt.ylabel('R² Score')\n    plt.axvline(x=best_alpha_r2, color='r', linestyle='--', alpha=0.3)\n    plt.grid(True)\n\n    plt.subplot(1, 2, 2)\n    plt.semilogx(ridge_results_df['alpha'], ridge_results_df['rmse'])\n    plt.title('Ridge Regression RMSE vs Alpha')\n    plt.xlabel('Alpha (log scale)')\n    plt.ylabel('RMSE')\n    plt.axvline(x=best_alpha_rmse, color='r', linestyle='--', alpha=0.3)\n    plt.grid(True)\n\n    plt.tight_layout()\n    plot_path = \"ridge_alpha_tuning.png\"\n    plt.savefig(plot_path)\n    mlflow.log_artifact(plot_path)\n    plt.show()\n\n    print(f\"Best alpha by R²: {best_alpha_r2:.4f} (R²: {best_r2:.4f})\")\n    print(f\"Best alpha by RMSE: {best_alpha_rmse:.4f} (RMSE: {best_rmse:.4f})\")\n    print(\"\\nTop 10 most important features:\")\n    print(ridge_coefs.head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Non Linear","metadata":{}},{"cell_type":"code","source":"import mlflow\nimport mlflow.sklearn\nimport pandas as pd\nimport numpy as np\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import cross_val_score\n\n# Set experiment\nmlflow.set_experiment(\"House Price Regression\")\n\n# Hyperparameters to evaluate\ndepths = [3, 5, 10, None]\nsplits = [2, 5, 10]\n\n# Begin MLflow run\nwith mlflow.start_run(run_name=\"Non Linear\"):\n    mlflow.log_param(\"model_type\", \"DecisionTree & RandomForest\")\n\n    print(\"Decision Tree Results:\")\n    dt_results = []\n    for depth in depths:\n        for split in splits:\n            dt = DecisionTreeRegressor(max_depth=depth, min_samples_split=split, random_state=0)\n            r2_scores = cross_val_score(dt, X_filtered, y_train, cv=5, scoring='r2')\n            mean_r2 = np.mean(r2_scores)\n\n            print(f\"DT: max_depth={depth}, min_samples_split={split} → R² = {mean_r2:.4f}\")\n            \n            # Log metrics to MLflow\n            mlflow.log_metric(f\"DT_r2_depth_{depth}_split_{split}\", mean_r2)\n\n            dt_results.append({\n                'model': 'DecisionTree',\n                'max_depth': depth,\n                'min_samples_split': split,\n                'r2': mean_r2\n            })\n\n    print(\"\\nRandom Forest Results:\")\n    rf_results = []\n    for depth in depths:\n        for split in splits:\n            rf = RandomForestRegressor(n_estimators=100, max_depth=depth, \n                                       min_samples_split=split, random_state=0)\n            r2_scores = cross_val_score(rf, X_filtered, y_train, cv=5, scoring='r2')\n            rmse_scores = -cross_val_score(rf, X_filtered, y_train, cv=5,\n                                           scoring='neg_root_mean_squared_error')\n\n            mean_r2 = np.mean(r2_scores)\n            mean_rmse = np.mean(rmse_scores)\n\n            print(f\"RF: max_depth={depth}, min_samples_split={split} → R² = {mean_r2:.4f}\")\n            print(f\"RF: max_depth={depth}, min_samples_split={split} → RMSE = {mean_rmse:.4f}\")\n\n            # Log metrics to MLflow\n            mlflow.log_metric(f\"RF_r2_depth_{depth}_split_{split}\", mean_r2)\n            mlflow.log_metric(f\"RF_rmse_depth_{depth}_split_{split}\", mean_rmse)\n\n            rf_results.append({\n                'model': 'RandomForest',\n                'max_depth': depth,\n                'min_samples_split': split,\n                'r2': mean_r2,\n                'rmse': mean_rmse\n            })\n\n    # Save full results to file and log\n    all_results_df = pd.DataFrame(dt_results + rf_results)\n    all_results_df.to_csv(\"non_linear_results.csv\", index=False)\n    mlflow.log_artifact(\"non_linear_results.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\n\n# Train model\nrf = RandomForestRegressor(max_depth=None, min_samples_split=2, random_state=0)\nrf.fit(X_filtered, y_train)\n\n# Evaluate\ntrain_r2 = r2_score(y_train, rf.predict(X_filtered))\ntest_r2 = r2_score(y_test, rf.predict(X_test_new))\n\nprint(f\"Training R²: {train_r2:.4f}\")\nprint(f\"Test R²:     {test_r2:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport mlflow\nimport mlflow.sklearn\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Set experiment\nmlflow.set_experiment(\"House Price Regression\")\n\nwith mlflow.start_run(run_name=\"Random Forest\"):\n\n    # Log model type as a parameter\n    mlflow.log_param(\"model_type\", \"RandomForestRegressor\")\n\n    # Data (replace with your real data if needed)\n    X = X_filtered\n    y = y_train\n\n    # Model setup\n    model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42)\n\n    # Get learning curve data\n    train_sizes, train_scores, test_scores = learning_curve(\n        model, X, y,\n        train_sizes=np.linspace(0.1, 1.0, 10),\n        cv=5,\n        scoring='r2',\n        n_jobs=-1,\n        shuffle=True,\n        random_state=42\n    )\n\n    # Compute means and stds\n    train_mean = np.mean(train_scores, axis=1)\n    train_std = np.std(train_scores, axis=1)\n    test_mean = np.mean(test_scores, axis=1)\n    test_std = np.std(test_scores, axis=1)\n\n    # Plotting\n    plt.figure(figsize=(10, 6))\n    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training R²')\n    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n\n    plt.plot(train_sizes, test_mean, 'o-', color='green', label='Cross-validation R²')\n    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='green')\n\n    plt.title('Learning Curve')\n    plt.xlabel('Training Set Size')\n    plt.ylabel('R² Score')\n    plt.legend(loc='best')\n    plt.grid(True)\n    plt.tight_layout()\n\n    # Save and log the plot\n    plot_path = \"learning_curve_rf.png\"\n    plt.savefig(plot_path)\n    mlflow.log_artifact(plot_path)\n    plt.close()\n\n    # Print the link to view in UI\n    run = mlflow.active_run()\n    print(\"View run at:\", f\"http://127.0.0.1:5000/#/experiments/{run.info.experiment_id}/runs/{run.info.run_id}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import cross_val_score\nimport numpy as np\n\n# Create the model\ngbr = GradientBoostingRegressor(\n    n_estimators=300,         # Number of boosting stages\n    learning_rate=0.05,       # Shrinks contribution of each tree\n    max_depth=3,              # Limits depth of individual trees\n    min_samples_split=5,      # Minimum samples required to split\n    min_samples_leaf=3,       # Minimum samples per leaf node\n    subsample=0.8,            # Use 80% of samples for fitting each tree\n    max_features='sqrt',      # Use sqrt(n_features) per tree (like RF)\n    random_state=42\n)\n\n# Fit and evaluate\ngbr.fit(X_filtered, y_train)\n\ntrain_r2 = gbr.score(X_filtered, y_train)\ntest_r2 = gbr.score(X_test_new, y_test)\ncv_r2 = cross_val_score(gbr, X_filtered, y_train, cv=5, scoring='r2')\n\nprint(f\"Training R²: {train_r2:.4f}\")\nprint(f\"Test R²:     {test_r2:.4f}\")\nprint(f\"CV R² (mean): {np.mean(cv_r2):.4f} ± {np.std(cv_r2):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import cross_val_score\nimport mlflow\nimport mlflow.sklearn\n\n# Set experiment\nmlflow.set_experiment(\"House Price Regression\")\n\nwith mlflow.start_run(run_name=\"Booster\"):\n\n    # Initialize the model\n    gbr = GradientBoostingRegressor(\n        n_estimators=300,\n        learning_rate=0.05,\n        max_depth=3,\n        min_samples_split=5,\n        min_samples_leaf=3,\n        subsample=0.8,\n        max_features='sqrt',\n        random_state=42\n    )\n\n    # Log model parameters\n    mlflow.log_param(\"model_type\", \"GradientBoostingRegressor\")\n    mlflow.log_params({\n        \"n_estimators\": 300,\n        \"learning_rate\": 0.05,\n        \"max_depth\": 3,\n        \"min_samples_split\": 5,\n        \"min_samples_leaf\": 3,\n        \"subsample\": 0.8,\n        \"max_features\": \"sqrt\",\n    })\n\n    # Fit the model\n    gbr.fit(X_filtered, y_train)\n\n    # Evaluate\n    train_r2 = gbr.score(X_filtered, y_train)\n    test_r2 = gbr.score(X_test_new, y_test)\n    cv_r2 = cross_val_score(gbr, X_filtered, y_train, cv=5, scoring='r2')\n\n    # Log metrics\n    mlflow.log_metric(\"train_r2\", train_r2)\n    mlflow.log_metric(\"test_r2\", test_r2)\n    mlflow.log_metric(\"cv_r2_mean\", np.mean(cv_r2))\n    mlflow.log_metric(\"cv_r2_std\", np.std(cv_r2))\n\n    mlflow.sklearn.log_model(gbr, \"model\")\n\n    # Optional: log CV scores as a CSV artifact\n    pd.DataFrame({'cv_r2_scores': cv_r2}).to_csv(\"cv_r2_scores.csv\", index=False)\n    mlflow.log_artifact(\"cv_r2_scores.csv\")\n\n    # Output\n    print(f\"Training R²: {train_r2:.4f}\")\n    print(f\"Test R²:     {test_r2:.4f}\")\n    print(f\"CV R² (mean): {np.mean(cv_r2):.4f} ± {np.std(cv_r2):.4f}\")\n\n    # Direct link\n    run = mlflow.active_run()\n    print(\"View run at:\", f\"http://127.0.0.1:5000/#/experiments/{run.info.experiment_id}/runs/{run.info.run_id}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\n\n# --- Assuming the model is already trained ---\n\n# Predict on test data\ny_pred = gbr.predict(X_test_new)\n\n# Calculate error\nerrors = y_pred - y_test\n\n# Create DataFrame for plotting\ndf_error = pd.DataFrame({\n    'Actual': y_test,\n    'Predicted': y_pred,\n    'Error': errors\n}).reset_index(drop=True)\n\n# Set seaborn style\nsns.set(style=\"whitegrid\")\n\n# Plot error bar chart\nplt.figure(figsize=(14, 6))\nsns.barplot(x=df_error.index, y='Error', data=df_error, palette='coolwarm')\nplt.axhline(0, color='black', linestyle='--')\nplt.title('Prediction Error Per House (Predicted - Actual)')\nplt.xlabel('House Index')\nplt.ylabel('Error')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport mlflow\nimport mlflow.sklearn\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\nfrom sklearn.metrics import r2_score, mean_squared_error\n\n# Define experiment\nmlflow.set_experiment(\"House Price Regression\")\n\nwith mlflow.start_run(run_name=\"Booster loss = huber\"):\n\n    # Model parameters\n    model_params = {\n        \"n_estimators\": 500,\n        \"learning_rate\": 0.05,\n        \"max_depth\": 2,\n        \"min_samples_split\": 15,\n        \"min_samples_leaf\": 8,\n        \"subsample\": 0.8,\n        \"max_features\": 'sqrt',\n        \"loss\": 'huber',\n        \"random_state\": 42\n    }\n\n    # Log parameters\n    mlflow.log_params(model_params)\n\n    # Create and train model\n    gbr = GradientBoostingRegressor(**model_params)\n    gbr.fit(X_filtered, y_train)\n\n    # Predictions\n    y_train_pred = gbr.predict(X_filtered)\n    y_test_pred = gbr.predict(X_test_new)\n    cv_preds = cross_val_predict(gbr, X_filtered, y_train, cv=5)\n\n    # Evaluation metrics\n    train_r2 = r2_score(y_train, y_train_pred)\n    test_r2 = r2_score(y_test, y_test_pred)\n    cv_r2_scores = cross_val_score(gbr, X_filtered, y_train, cv=5, scoring='r2')\n    cv_r2_mean = np.mean(cv_r2_scores)\n    cv_r2_std = np.std(cv_r2_scores)\n\n    # Log metrics\n    mlflow.log_metric(\"train_r2\", train_r2)\n    mlflow.log_metric(\"test_r2\", test_r2)\n    mlflow.log_metric(\"cv_r2_mean\", cv_r2_mean)\n    mlflow.log_metric(\"cv_r2_std\", cv_r2_std)\n\n    print(f\"Training R²: {train_r2:.4f}\")\n    print(f\"Test R²:     {test_r2:.4f}\")\n    print(f\"CV R² (mean): {cv_r2_mean:.4f} ± {cv_r2_std:.4f}\")\n\n    # Residual plots\n    plt.figure(figsize=(12, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.scatter(range(len(y_train)), y_train_pred - y_train, alpha=0.6)\n    plt.axhline(0, linestyle='--', color='black')\n    plt.title(\"Training Residuals\")\n    plt.xlabel(\"House #\")\n    plt.ylabel(\"Error (Predicted - Actual)\")\n\n    plt.subplot(1, 2, 2)\n    plt.scatter(range(len(y_train)), cv_preds - y_train, alpha=0.6, color='orange')\n    plt.axhline(0, linestyle='--', color='black')\n    plt.title(\"CV Residuals\")\n    plt.xlabel(\"House #\")\n    plt.ylabel(\"Error (Predicted - Actual)\")\n\n    plt.tight_layout()\n    plot_path = \"residuals_plot.png\"\n    plt.savefig(plot_path)\n    mlflow.log_artifact(plot_path)\n    plt.show()\n\n    # Log model\n    mlflow.sklearn.log_model(gbr, \"gradient_boosting_model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport mlflow\nimport mlflow.sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Split training set for early stopping\nX_train2, X_val, y_train2, y_val = train_test_split(X_filtered, y_train, test_size=0.2, random_state=42)\n\n# Set up MLflow\nmlflow.set_experiment(\"House Price Regression\")\n\nwith mlflow.start_run(run_name=\"Booster early stopping\"):\n\n    base_params = {\n        \"n_estimators\": 1000,\n        \"learning_rate\": 0.05,\n        \"max_depth\": 2,\n        \"min_samples_split\": 15,\n        \"min_samples_leaf\": 8,\n        \"subsample\": 0.8,\n        \"max_features\": 'sqrt',\n        \"loss\": 'huber',\n        \"random_state\": 42\n    }\n\n    mlflow.log_params(base_params)\n\n    # Train model with full estimators for early stopping\n    gbr_es = GradientBoostingRegressor(**base_params)\n    gbr_es.fit(X_train2, y_train2)\n\n    # Track validation error at each stage\n    errors = []\n    for y_pred in gbr_es.staged_predict(X_val):\n        errors.append(mean_squared_error(y_val, y_pred))\n\n    # Log all validation errors\n    for i, e in enumerate(errors):\n        mlflow.log_metric(\"val_mse\", e, step=i)\n\n    best_n = np.argmin(errors)\n    best_val_mse = errors[best_n]\n\n    print(f\"Best number of trees: {best_n}\")\n    mlflow.log_param(\"early_stopped_n_estimators\", best_n)\n    mlflow.log_metric(\"best_val_mse\", best_val_mse)\n\n    # Retrain with best_n on full training data\n    gbr_final = GradientBoostingRegressor(**{**base_params, \"n_estimators\": best_n})\n    gbr_final.fit(X_filtered, y_train)\n\n    train_r2 = gbr_final.score(X_filtered, y_train)\n    test_r2 = gbr_final.score(X_test_new, y_test)\n\n    print(f\"Final Training R²: {train_r2:.4f}\")\n    print(f\"Final Test R²:     {test_r2:.4f}\")\n\n    mlflow.log_metric(\"final_train_r2\", train_r2)\n    mlflow.log_metric(\"final_test_r2\", test_r2)\n\n    # Plot validation error\n    plt.figure(figsize=(8, 5))\n    plt.plot(errors, label='Validation MSE')\n    plt.axvline(best_n, linestyle='--', color='red', label=f'Best n = {best_n}')\n    plt.xlabel(\"Number of Trees\")\n    plt.ylabel(\"Validation MSE\")\n    plt.title(\"Validation Error over Boosting Stages\")\n    plt.legend()\n    plot_path = \"early_stopping_curve.png\"\n    plt.savefig(plot_path)\n    mlflow.log_artifact(plot_path)\n    plt.close()\n\n    # Log model\n    mlflow.sklearn.log_model(gbr_final, \"final_model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\n\n# Predict on test set\ny_pred = gbr_final.predict(X_test_new)\n\n# Calculate residuals\nresiduals = y_test - y_pred\n\n# Plot\nplt.figure(figsize=(10, 6))\nplt.scatter(range(len(residuals)), residuals, alpha=0.7, color='teal', edgecolors='k')\nplt.axhline(0, color='red', linestyle='--', linewidth=2)\nplt.title(\"Residual Plot (Actual - Predicted)\", fontsize=14)\nplt.xlabel(\"House Index\", fontsize=12)\nplt.ylabel(\"Residual Error\", fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}